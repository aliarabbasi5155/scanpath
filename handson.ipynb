{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fork_000000537944.jpg': [56, 229, 33, 49],\n",
       " 'knife_000000233539.jpg': [372, 193, 114, 92],\n",
       " 'tv_000000192651.jpg': [51, 138, 60, 54],\n",
       " 'laptop_000000335308.jpg': [16, 210, 52, 39],\n",
       " 'sink_000000164725.jpg': [158, 219, 159, 94],\n",
       " 'fork_000000061672.jpg': [383, 101, 51, 141],\n",
       " 'laptop_000000204979.jpg': [48, 98, 130, 101],\n",
       " 'mouse_000000539056.jpg': [386, 206, 41, 44],\n",
       " 'fork_000000323370.jpg': [399, 55, 65, 184],\n",
       " 'tv_000000203160.jpg': [98, 57, 71, 71]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bbox_annos = np.load(\"./files/Google Drive/bbox_annos.npy\", allow_pickle=True).item()\n",
    "bbox_annos_sample = {key: bbox_annos[key] for key in list(bbox_annos.keys())[:10]}\n",
    "bbox_annos_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "bbox_annos = np.load(\"./files/Google Drive/bbox_annos.npy\", allow_pickle=True).item()\n",
    "bbox_annos_sample = {key: bbox_annos[key] for key in list(bbox_annos.keys())[:10]}\n",
    "bbox_annos_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been split and written to the respective files.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Replace 'data.json' with the path to your original JSON file\n",
    "with open('files/DCBs_JSONs/dataset_test/SAIL_fixations_TP_train.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Shuffle the data to ensure random splitting\n",
    "random.shuffle(data)\n",
    "\n",
    "# Calculate the split index for 80/20 split\n",
    "split_index = int(len(data) * 0.8)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data = data[:split_index]\n",
    "valid_data = data[split_index:]\n",
    "\n",
    "# Write the training data to 'human_scanpath_train_split.json'\n",
    "with open('files/human_scanpath_train_split.json', 'w') as train_file:\n",
    "    json.dump(train_data, train_file, indent=4)\n",
    "\n",
    "# Write the validation data to 'human_scanpath_valid_split.json'\n",
    "with open('files/human_scanpath_valid_split.json', 'w') as valid_file:\n",
    "    json.dump(valid_data, valid_file, indent=4)\n",
    "\n",
    "print(\"Data has been split and written to the respective files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries checked: 198\n",
      "Entries with values exceeding thresholds: 0\n",
      "\n",
      "No entries have values exceeding the specified thresholds.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = 'fixation_data.json'\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(json_file_path):\n",
    "    print(f\"File not found: {json_file_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Load the JSON data\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize counters and lists to store entries exceeding thresholds\n",
    "entries_exceeding_threshold = []\n",
    "total_entries = len(data)\n",
    "entries_with_exceeding_values = 0\n",
    "\n",
    "# Thresholds\n",
    "x_threshold = 512\n",
    "y_threshold = 320\n",
    "\n",
    "# Iterate over each entry in the data\n",
    "for idx, entry in enumerate(data):\n",
    "    X_values = entry.get('X', [])\n",
    "    Y_values = entry.get('Y', [])\n",
    "    entry_name = entry.get('name', f'Entry {idx}')\n",
    "\n",
    "    # Flags to check if any value exceeds the thresholds\n",
    "    x_exceeds = any(x > x_threshold for x in X_values)\n",
    "    y_exceeds = any(y > y_threshold for y in Y_values)\n",
    "\n",
    "    # If any value exceeds the thresholds, store the entry information\n",
    "    if x_exceeds or y_exceeds:\n",
    "        entries_with_exceeding_values += 1\n",
    "        entries_exceeding_threshold.append({\n",
    "            'entry_index': idx,\n",
    "            'name': entry_name,\n",
    "            'X_exceeds': [x for x in X_values if x > x_threshold],\n",
    "            'Y_exceeds': [y for y in Y_values if y > y_threshold]\n",
    "        })\n",
    "\n",
    "# Reporting the results\n",
    "print(f\"Total entries checked: {total_entries}\")\n",
    "print(f\"Entries with values exceeding thresholds: {entries_with_exceeding_values}\\n\")\n",
    "\n",
    "if entries_exceeding_threshold:\n",
    "    print(\"Entries exceeding thresholds:\")\n",
    "    for item in entries_exceeding_threshold:\n",
    "        print(f\"\\nEntry Index: {item['entry_index']}\")\n",
    "        print(f\"Name: {item['name']}\")\n",
    "        if item['X_exceeds']:\n",
    "            print(f\"X values exceeding {x_threshold}: {item['X_exceeds']}\")\n",
    "        if item['Y_exceeds']:\n",
    "            print(f\"Y values exceeding {y_threshold}: {item['Y_exceeds']}\")\n",
    "else:\n",
    "    print(\"No entries have values exceeding the specified thresholds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been filtered, split, and written to the respective files.\n",
      "Total entries after filtering: 257 and 10 entries were removed.\n",
      "Training entries: 205\n",
      "Validation entries: 52\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = 'DCBs_JSONs/dataset_test/SAIL_fixations_TA_train.json'\n",
    "\n",
    "# Output file paths\n",
    "train_file_path = 'human_scanpath_train_split.json'\n",
    "valid_file_path = 'human_scanpath_valid_split.json'\n",
    "\n",
    "# Check if the input file exists\n",
    "if not os.path.exists(json_file_path):\n",
    "    print(f\"File not found: {json_file_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Load the JSON data\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Thresholds\n",
    "x_threshold = 512\n",
    "y_threshold = 320\n",
    "\n",
    "# Filter entries that have no X[i] > 512 and no Y[i] > 320\n",
    "filtered_data = []\n",
    "for idx, entry in enumerate(data):\n",
    "    X_values = entry.get('X', [])\n",
    "    Y_values = entry.get('Y', [])\n",
    "\n",
    "    # Check if any X[i] > 512 or Y[i] > 320\n",
    "    x_exceeds = any(x > x_threshold for x in X_values)\n",
    "    y_exceeds = any(y > y_threshold for y in Y_values)\n",
    "\n",
    "    if not x_exceeds and not y_exceeds:\n",
    "        filtered_data.append(entry)\n",
    "\n",
    "# Shuffle the filtered data\n",
    "random.shuffle(filtered_data)\n",
    "\n",
    "# Calculate the split index for 80/20 split\n",
    "split_index = int(len(filtered_data) * 0.8)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data = filtered_data[:split_index]\n",
    "valid_data = filtered_data[split_index:]\n",
    "\n",
    "# Update the 'split' field in each entry\n",
    "for entry in train_data:\n",
    "    entry['split'] = 'train'\n",
    "\n",
    "for entry in valid_data:\n",
    "    entry['split'] = 'valid'\n",
    "\n",
    "# Write the training data to 'human_scanpath_train_split.json'\n",
    "with open(train_file_path, 'w') as train_file:\n",
    "    json.dump(train_data, train_file, indent=4)\n",
    "\n",
    "# Write the validation data to 'human_scanpath_valid_split.json'\n",
    "with open(valid_file_path, 'w') as valid_file:\n",
    "    json.dump(valid_data, valid_file, indent=4)\n",
    "\n",
    "print(\"Data has been filtered, split, and written to the respective files.\")\n",
    "print(f\"Total entries after filtering: {len(filtered_data)} and {len(data) - len(filtered_data)} entries were removed.\")\n",
    "print(f\"Training entries: {len(train_data)}\")\n",
    "print(f\"Validation entries: {len(valid_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been filtered, split, and written to the respective files.\n",
      "Total entries after filtering: 142 and 56 entries were removed.\n",
      "Training entries: 113\n",
      "Validation entries: 29\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = 'fixation_data.json'\n",
    "\n",
    "# Output file paths\n",
    "train_file_path = 'stroop_human_scanpath_train_split.json'\n",
    "valid_file_path = 'stroop_human_scanpath_valid_split.json'\n",
    "\n",
    "# Check if the input file exists\n",
    "if not os.path.exists(json_file_path):\n",
    "    print(f\"File not found: {json_file_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Load the JSON data\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Add 'featureA', 'featureB', and 'featureC' to each entry\n",
    "for entry in data:\n",
    "    # length = entry.get('length', 0)\n",
    "    length = 3\n",
    "    # Ensure length is an integer and greater than 0\n",
    "    if isinstance(length, int) and length > 0:\n",
    "        # Generate random values between 0 and 1\n",
    "        entry['eeg_data'] = [random.random() for _ in range(length)]\n",
    "    else:\n",
    "        # Handle entries without valid 'length'\n",
    "        entry['eeg_data'] = []\n",
    "\n",
    "# Thresholds\n",
    "x_threshold = 512\n",
    "y_threshold = 320\n",
    "\n",
    "# Filter entries that have no X[i] > 512 and no Y[i] > 320\n",
    "filtered_data = []\n",
    "for idx, entry in enumerate(data):\n",
    "    X_values = entry.get('X', [])\n",
    "    Y_values = entry.get('Y', [])\n",
    "\n",
    "    # Check if any X[i] > 512 or Y[i] > 320\n",
    "    x_exceeds = any(x > x_threshold for x in X_values)\n",
    "    y_exceeds = any(y > y_threshold for y in Y_values)\n",
    "\n",
    "    if not x_exceeds and not y_exceeds:\n",
    "        filtered_data.append(entry)\n",
    "\n",
    "# Shuffle the filtered data\n",
    "random.shuffle(filtered_data)\n",
    "\n",
    "# Calculate the split index for 80/20 split\n",
    "split_index = int(len(filtered_data) * 0.8)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data = filtered_data[:split_index]\n",
    "valid_data = filtered_data[split_index:]\n",
    "\n",
    "# Update the 'split' field in each entry\n",
    "for entry in train_data:\n",
    "    entry['split'] = 'train'\n",
    "\n",
    "for entry in valid_data:\n",
    "    entry['split'] = 'valid'\n",
    "\n",
    "# Write the training data to 'human_scanpath_train_split.json'\n",
    "with open(train_file_path, 'w') as train_file:\n",
    "    json.dump(train_data, train_file, indent=4)\n",
    "\n",
    "# Write the validation data to 'human_scanpath_valid_split.json'\n",
    "with open(valid_file_path, 'w') as valid_file:\n",
    "    json.dump(valid_data, valid_file, indent=4)\n",
    "\n",
    "print(\"Data has been filtered, split, and written to the respective files.\")\n",
    "print(f\"Total entries after filtering: {len(filtered_data)} and {len(data) - len(filtered_data)} entries were removed.\")\n",
    "print(f\"Training entries: {len(train_data)}\")\n",
    "print(f\"Validation entries: {len(valid_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_slides: ['Slide1.jpg', 'Slide3.jpg', 'Slide5.jpg', 'Slide7.jpg', 'Slide9.jpg', 'Slide11.jpg', 'Slide13.jpg', 'Slide15.jpg', 'Slide17.jpg', 'Slide19.jpg', 'Slide21.jpg', 'Slide23.jpg', 'Slide25.jpg', 'Slide27.jpg', 'Slide29.jpg', 'Slide31.jpg', 'Slide33.jpg', 'Slide35.jpg', 'Slide37.jpg']\n",
      "Subject 1 has all the slides.\n",
      "Subject 2 has all the slides.\n",
      "Subject 3 is missing the following slides: Slide19.jpg, Slide21.jpg\n",
      "Subject 4 has all the slides.\n",
      "Subject 5 has all the slides.\n",
      "Subject 6 has all the slides.\n",
      "Subject 7 is missing the following slides: Slide1.jpg, Slide3.jpg, Slide5.jpg, Slide7.jpg, Slide9.jpg, Slide11.jpg, Slide13.jpg, Slide15.jpg, Slide17.jpg, Slide19.jpg, Slide21.jpg, Slide23.jpg, Slide25.jpg, Slide27.jpg, Slide29.jpg, Slide31.jpg, Slide33.jpg, Slide35.jpg, Slide37.jpg\n",
      "Subject 8 has all the slides.\n",
      "Subject 9 has all the slides.\n",
      "Subject 10 has all the slides.\n",
      "Subject 11 has all the slides.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = 'fixation_data.json'\n",
    "\n",
    "# Output file paths\n",
    "train_file_path = 'stroop_human_scanpath_train_split.json'\n",
    "valid_file_path = 'stroop_human_scanpath_valid_split.json'\n",
    "\n",
    "# Check if the input file exists\n",
    "if not os.path.exists(json_file_path):\n",
    "    print(f\"File not found: {json_file_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Load the JSON data\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Thresholds\n",
    "x_threshold = 512\n",
    "y_threshold = 320\n",
    "\n",
    "# Filter entries that have no X[i] > 512 and no Y[i] > 320\n",
    "filtered_data = []\n",
    "removed_entries = []\n",
    "\n",
    "\n",
    "# Create the list of slides ['Slide1.jpg', 'Slide3.jpg', ..., 'Slide59.jpg']\n",
    "target_slides = [f'Slide{2*i-1}.jpg' for i in range(1, 20)]\n",
    "print(\"target_slides: \" + str(target_slides))\n",
    "\n",
    "# Create a dictionary to track which slides each subject has\n",
    "subjects_slides = {subject: set() for subject in range(1, 12)}\n",
    "\n",
    "# Populate the dictionary with available slides for each subject\n",
    "for record in data:\n",
    "    subject = record['subject']\n",
    "    slide_name = record['name']\n",
    "    if subject in subjects_slides:\n",
    "        subjects_slides[subject].add(slide_name)\n",
    "\n",
    "# Now check for each subject which slides are missing\n",
    "for subject in range(1, 12):\n",
    "    available_slides = subjects_slides[subject]\n",
    "    missing_slides = [slide for slide in target_slides if slide not in available_slides]\n",
    "    \n",
    "    if missing_slides:\n",
    "        print(f\"Subject {subject} is missing the following slides: {', '.join(missing_slides)}\")\n",
    "    else:\n",
    "        print(f\"Subject {subject} has all the slides.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def read_csv(file_path):\n",
    "    # Read CSV file with comma delimiter\n",
    "    df = pd.read_csv(file_path, delimiter=',')\n",
    "    # Clean column names to remove leading/trailing whitespaces and standardize them\n",
    "    df.columns = df.columns.str.strip().str.upper()\n",
    "    return df\n",
    "\n",
    "def extract_rows(df, start, end, time_column):\n",
    "    # Convert time column to numeric\n",
    "    df['timestamp'] = pd.to_numeric(df[time_column], errors='coerce')\n",
    "    # Drop rows with NaN values in 'timestamp' due to conversion issues\n",
    "    df.dropna(subset=['timestamp'], inplace=True)\n",
    "    # Extract rows within the given time range\n",
    "    mask = (df['timestamp'] >= start) & (df['timestamp'] <= end)\n",
    "    return df[mask]\n",
    "\n",
    "def is_within_bbox(x, y, bbox):\n",
    "    x_min, y_min, width, height = bbox\n",
    "    x_max = x_min + width\n",
    "    y_max = y_min + height\n",
    "\n",
    "    # Ensure that x_min <= x_max and y_min <= y_max\n",
    "    x_min, x_max = sorted([x_min, x_max])\n",
    "    y_min, y_max = sorted([y_min, y_max])\n",
    "\n",
    "    return x_min <= x <= x_max and y_min <= y <= y_max\n",
    "\n",
    "def generate_json_entry(name, subject, task, condition, bbox, filtered_df, cx_column, cy_column, duration_column, start_time_in_sec, end_time_in_sec, time_range_in_minutes):\n",
    "    # X_real = filtered_df[cx_column].tolist()\n",
    "    # Y_real = filtered_df[cy_column].tolist()\n",
    "    # Hey chatgpt, Here I want if each if any of X or Y is less than zero put is as zero. For example \n",
    "    # if X is -2 put it as 0 and if Y is -3 put it as 0.\n",
    "    X = [(min(max(0, x * 512),511)) for x in filtered_df[cx_column].tolist()]\n",
    "    Y = [(min(max(0, y * 320),319)) for y in filtered_df[cy_column].tolist()]\n",
    "    T = filtered_df[duration_column].tolist()\n",
    "    length = len(X)\n",
    "    correct = any(is_within_bbox(X[i], Y[i], bbox) for i in range(length))\n",
    "    \n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"subject\": subject,\n",
    "        # \"time_range_in_seconds\": [start_time_in_sec, end_time_in_sec],\n",
    "        # \"time_range_in_minutes\": time_range_in_minutes,\n",
    "        \"task\": task,\n",
    "        \"condition\": condition,\n",
    "        \"bbox\": bbox,\n",
    "        # \"X_real\": X_real,\n",
    "        # \"Y_real\": Y_real, \n",
    "        \"X\": X,\n",
    "        \"Y\": Y,\n",
    "        \"T\": T,\n",
    "        \"length\": length,\n",
    "        \"correct\": int(correct),\n",
    "        \"split\": \"train\"\n",
    "    }\n",
    "\n",
    "def convert_time_to_seconds(time_str):\n",
    "    # Convert time format (HH:MM:SS:MS) to seconds\n",
    "    hours, minutes, seconds, milliseconds = map(int, time_str.split(':'))\n",
    "    return hours * 3600 + minutes * 60 + seconds + milliseconds / 1000\n",
    "\n",
    "def extract_fixations(file_paths, entries, width=512, height=320):\n",
    "    results = []\n",
    "    BPOGX_column = 'BPOGX'\n",
    "    BPOGY_column = 'BPOGY'\n",
    "    time_column = 'FPOGD'\n",
    "\n",
    "    for entry in entries:\n",
    "        subject = entry['subject']\n",
    "        file_path = file_paths.get(subject)\n",
    "        if not file_path:\n",
    "            continue\n",
    "\n",
    "        df = read_csv(file_path)\n",
    "\n",
    "        if BPOGX_column not in df.columns or BPOGY_column not in df.columns or time_column not in df.columns:\n",
    "            raise KeyError(\"Columns 'BPOGX', 'BPOGY', or 'FPOGD' not found in CSV file.\")\n",
    "\n",
    "        name = entry['name']\n",
    "        update_dict = {\n",
    "            \"Slide1.jpg\": \"congruent\",\n",
    "            \"Slide3.jpg\": \"incongruent\",\n",
    "            \"Slide5.jpg\": \"congruent\", \n",
    "            \"Slide7.jpg\": \"congruent\",\n",
    "            \"Slide9.jpg\": \"incongruent\",\n",
    "            \"Slide11.jpg\": \"congruent\",\n",
    "            \"Slide13.jpg\": \"incongruent\",\n",
    "            \"Slide15.jpg\": \"incongruent\",\n",
    "            \"Slide17.jpg\": \"incongruent\",\n",
    "            \"Slide19.jpg\": \"incongruent\",\n",
    "            \"Slide21.jpg\": \"congruent\",\n",
    "            \"Slide23.jpg\": \"incongruent\",\n",
    "            \"Slide25.jpg\": \"congruent\",\n",
    "            \"Slide27.jpg\": \"incongruent\",\n",
    "            \"Slide29.jpg\": \"congruent\",\n",
    "            \"Slide31.jpg\": \"incongruent\",\n",
    "            \"Slide33.jpg\": \"congruent\",\n",
    "            \"Slide35.jpg\": \"incongruent\",\n",
    "            \"Slide37.jpg\": \"incongruent\",\n",
    "            \"Slide39.jpg\": \"congruent\",\n",
    "        }\n",
    "        task = entry['task']\n",
    "        entry[\"task\"] = update_dict[name]\n",
    "        condition = entry['condition']\n",
    "        bbox_indicator = entry['bbox_indicator']\n",
    "        bbox = [181, 10, 149, 33] if bbox_indicator == 1 else [181, 276, 149, 34]\n",
    "        start, end = entry['time_range']\n",
    "\n",
    "        # Convert time range to seconds\n",
    "        start_time = convert_time_to_seconds(start)\n",
    "        end_time = convert_time_to_seconds(end)\n",
    "\n",
    "        filtered_df = extract_rows(df, start_time, end_time, 'FPOGS')\n",
    "        json_entry = generate_json_entry(name, subject, task, condition, bbox, filtered_df, BPOGX_column, BPOGY_column, time_column, start_time, end_time, entry['time_range'])\n",
    "        if not filtered_df.empty: # Subject 3 Slide19 and Slide21 have empty fixations\n",
    "            results.append(json_entry)\n",
    "\n",
    "    # Limit the size of the JSON by rounding values to reduce length\n",
    "    for entry in results:\n",
    "        entry['X'] = [round(x, 2) for x in entry['X']]\n",
    "        entry['Y'] = [round(y, 2) for y in entry['Y']]\n",
    "        entry['T'] = [round(t*1000) for t in entry['T']]\n",
    "    \n",
    "    return results\n",
    "\n",
    "# List of file paths for each subject\n",
    "file_paths = {\n",
    "    1: '/home/ali/Repos/Scanpath_Prediction/files/Raw_Gaze_Data/P1/GAZE/result/User 0_fixations.csv',\n",
    "    2: '/home/ali/Repos/Scanpath_Prediction/files/Raw_Gaze_Data/P2/GAZE/result/User 2_fixations.csv',\n",
    "    3: '/home/ali/Repos/Scanpath_Prediction/files/Raw_Gaze_Data/P3/GAZE/result/User 1_fixations.csv',\n",
    "    4: '/home/ali/Repos/Scanpath_Prediction/files/Raw_Gaze_Data/P4/GAZE/result/User 0_fixations.csv',\n",
    "    5: '/home/ali/Repos/Scanpath_Prediction/files/Raw_Gaze_Data/P5/GAZE/result/User 0_fixations.csv',\n",
    "    6: '/home/ali/Repos/Scanpath_Prediction/files/Raw_Gaze_Data/P6/Raw Data/GAZE/result/User 0_fixations.csv',\n",
    "    8: '/home/ali/Repos/Scanpath_Prediction/files/Raw_Gaze_Data/P8/GAZE/result/User 0_fixations.csv',\n",
    "    9: '/home/ali/Repos/Scanpath_Prediction/files/Raw_Gaze_Data/P9/GAZE/result/User 1_fixations.csv',\n",
    "    10: '/home/ali/Repos/Scanpath_Prediction/files/Raw_Gaze_Data/P10/GAZE/result/User 0_fixations.csv',\n",
    "    11: '/home/ali/Repos/Scanpath_Prediction/files/Raw_Gaze_Data/P11/GAZE/result/User 0_fixations.csv',\n",
    "}\n",
    "\n",
    "# Load list of entries for fixation extraction from JSON file\n",
    "with open('entries_corrected.json', 'r') as entries_file:\n",
    "    entries = json.load(entries_file)\n",
    "\n",
    "# Extract and scale fixation data\n",
    "fixation_data = extract_fixations(file_paths, entries)\n",
    "\n",
    "# Convert result to JSON\n",
    "with open('fixation_data.json', 'w') as json_file:\n",
    "    json.dump(fixation_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses only for entring data to make all of the times to zero.\n",
    "# import json\n",
    "\n",
    "# # Read the JSON file\n",
    "# with open('entries.json', 'r') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# # Modify the time_range for each entry\n",
    "# for entry in data:\n",
    "#     entry['time_range'] = [\"00:00:00:00\", \"00:00:00:00\"]\n",
    "\n",
    "# # Write to the new JSON file with the time_range in a single line\n",
    "# with open('entries_corrected.json', 'w') as file:\n",
    "#     json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated entries saved to fixation_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to update bbox_indicator based on the given dictionary\n",
    "def update_bbox_indicator(file_path, update_dict):\n",
    "    # Load the JSON data from file\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Loop through each entry in the JSON data\n",
    "    for entry in data:\n",
    "        name = entry.get(\"name\")\n",
    "        # Check if the name is in the update dictionary\n",
    "        if name in update_dict:\n",
    "            # Update bbox_indicator with the value from the dictionary\n",
    "            entry[\"task\"] = update_dict[name]\n",
    "    \n",
    "    # Write the updated data back to the JSON file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(f\"Updated entries saved to {file_path}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = 'fixation_data.json'\n",
    "update_dict = {\n",
    "    \"Slide1.jpg\": \"congruent\",\n",
    "    \"Slide3.jpg\": \"incongruent\",\n",
    "    \"Slide5.jpg\": \"congruent\", \n",
    "    \"Slide7.jpg\": \"congruent\",\n",
    "    \"Slide9.jpg\": \"incongruent\",\n",
    "    \"Slide11.jpg\": \"congruent\",\n",
    "    \"Slide13.jpg\": \"incongruent\",\n",
    "    \"Slide15.jpg\": \"incongruent\",\n",
    "    \"Slide17.jpg\": \"incongruent\",\n",
    "    \"Slide19.jpg\": \"incongruent\",\n",
    "    \"Slide21.jpg\": \"congruent\",\n",
    "    \"Slide23.jpg\": \"incongruent\",\n",
    "    \"Slide25.jpg\": \"congruent\",\n",
    "    \"Slide27.jpg\": \"incongruent\",\n",
    "    \"Slide29.jpg\": \"congruent\",\n",
    "    \"Slide31.jpg\": \"incongruent\",\n",
    "    \"Slide33.jpg\": \"congruent\",\n",
    "    \"Slide35.jpg\": \"incongruent\",\n",
    "    \"Slide37.jpg\": \"incongruent\",\n",
    "    \"Slide39.jpg\": \"congruent\",\n",
    "}\n",
    "\n",
    "update_bbox_indicator(file_path, update_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in Excel file: Index(['id', 'F1', 'F2', 'F3', 'labels'], dtype='object')\n",
      "JSON file updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set Correct EEGs of the Stroop to the fixation_data.json\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON data\n",
    "with open(\"fixation_data.json\", \"r\") as json_file:\n",
    "    fixation_data = json.load(json_file)\n",
    "\n",
    "# Load the Excel data\n",
    "excel_data = pd.read_excel(\"files/MostImpEEG_Stroop.xlsx\")\n",
    "\n",
    "# Print column names to inspect them\n",
    "print(\"Column names in Excel file:\", excel_data.columns)\n",
    "\n",
    "# Assuming the columns are not labeled B, C, D, and E, replace them with actual column names\n",
    "# Iterate over each JSON record and update based on Excel data\n",
    "excel_index = 0  # Start from the first row in the Excel file\n",
    "skipped_ids = {48, 49}  # Corresponding IDs for subject 3, slides 19 and 21\n",
    "\n",
    "for record in fixation_data:\n",
    "    subject = record[\"subject\"]\n",
    "    slide_number = int(record[\"name\"].replace(\"Slide\", \"\").replace(\".jpg\", \"\"))\n",
    "    \n",
    "    # Calculate the id based on subject and slide\n",
    "    record_id = (subject - 1) * 20 + (slide_number // 2) + 1\n",
    "    \n",
    "\n",
    "    \n",
    "    # Update 'eeg_data' field from F1, F2, and F3 in the Excel file\n",
    "    record[\"eeg_data\"] = [\n",
    "        excel_data.iloc[excel_index][excel_data.columns[1]],  # F1\n",
    "        excel_data.iloc[excel_index][excel_data.columns[2]],  # F2\n",
    "        excel_data.iloc[excel_index][excel_data.columns[3]],  # F3\n",
    "    ]\n",
    "\n",
    "\n",
    "    # I have disabled this currently. I have set in another place\n",
    "    # Update 'correct' field based on label\n",
    "    # label = excel_data.iloc[excel_index][excel_data.columns[4]]\n",
    "    # record[\"task\"] = \"congruent\" if label == \"C\" else \"incongruent\"\n",
    "    # print(f\"subject:{subject} slide_number:{slide_number} record_id:{record_id}\" + \n",
    "    #       f\"excel_index:{excel_index} eeg:{record[\"eeg_data\"]}\")\n",
    "    \n",
    "    # Skip specific slides for subject 3 (slide 19 and slide 21)\n",
    "    if subject == 3 and slide_number == 17:\n",
    "        excel_index += 3\n",
    "        continue\n",
    "    # Increment Excel index to move to the next row\n",
    "    else:\n",
    "        excel_index += 1\n",
    "\n",
    "# Save the updated JSON data\n",
    "with open(\"fixation_data.json\", \"w\") as json_file:\n",
    "    json.dump(fixation_data, json_file, indent=4)\n",
    "\n",
    "print(\"JSON file updated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'congruent_Slide1.jpg': [181, 10, 149, 33], 'incongruent_Slide3.jpg': [181, 276, 149, 34], 'congruent_Slide5.jpg': [181, 10, 149, 33], 'congruent_Slide7.jpg': [181, 10, 149, 33], 'incongruent_Slide9.jpg': [181, 276, 149, 34], 'congruent_Slide11.jpg': [181, 10, 149, 33], 'incongruent_Slide13.jpg': [181, 276, 149, 34], 'incongruent_Slide15.jpg': [181, 276, 149, 34], 'incongruent_Slide17.jpg': [181, 276, 149, 34], 'incongruent_Slide19.jpg': [181, 276, 149, 34], 'congruent_Slide21.jpg': [181, 10, 149, 33], 'incongruent_Slide23.jpg': [181, 276, 149, 34], 'congruent_Slide25.jpg': [181, 10, 149, 33], 'incongruent_Slide27.jpg': [181, 276, 149, 34], 'congruent_Slide29.jpg': [181, 10, 149, 33], 'incongruent_Slide31.jpg': [181, 276, 149, 34], 'congruent_Slide33.jpg': [181, 10, 149, 33], 'incongruent_Slide35.jpg': [181, 276, 149, 34], 'incongruent_Slide37.jpg': [181, 276, 149, 34], 'congruent_Slide39.jpg': [181, 10, 149, 33]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load the JSON file\n",
    "with open('fixation_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create a dictionary to store the data in the desired format\n",
    "bbox_annos = {}\n",
    "\n",
    "# Extract the necessary fields and populate the dictionary\n",
    "for entry in data:\n",
    "    name = entry['name']\n",
    "    task = entry['task']\n",
    "    bbox = entry['bbox']\n",
    "    \n",
    "    # Combine name and task to create a unique key for each entry\n",
    "    key = f\"{task}_{name}\"\n",
    "    bbox_annos[key] = bbox\n",
    "\n",
    "# Save the dictionary as a .npy file\n",
    "np.save('files/Stroop_DataSet/bbox_annos.npy', bbox_annos)\n",
    "\n",
    "# To load and verify the .npy file\n",
    "loaded_bbox_annos = np.load('files/Stroop_DataSet/bbox_annos.npy', allow_pickle=True).item()\n",
    "print(loaded_bbox_annos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Valid Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been filtered, split, and written to the respective files.\n",
      "Total entries after filtering: 198\n",
      "Training entries: 158\n",
      "Validation entries: 40\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = 'fixation_data.json'\n",
    "\n",
    "# Output file paths\n",
    "train_file_path = 'files/Stroop_DataSet/stroop_human_scanpath_train_split.json'\n",
    "valid_file_path = 'files/Stroop_DataSet/stroop_human_scanpath_valid_split.json'\n",
    "\n",
    "# Check if the input file exists\n",
    "if not os.path.exists(json_file_path):\n",
    "    print(f\"File not found: {json_file_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Load the JSON data\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "random.seed(42)\n",
    "# Shuffle the filtered data\n",
    "random.shuffle(data)\n",
    "\n",
    "# Calculate the split index for 80/20 split\n",
    "split_index = int(len(data) * 0.8)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data = data[:split_index]\n",
    "valid_data = data[split_index:]\n",
    "\n",
    "# Update the 'split' field in each entry\n",
    "for entry in train_data:\n",
    "    entry['split'] = 'train'\n",
    "\n",
    "for entry in valid_data:\n",
    "    entry['split'] = 'valid'\n",
    "\n",
    "# Write the training data to 'human_scanpath_train_split.json'\n",
    "with open(train_file_path, 'w') as train_file:\n",
    "    json.dump(train_data, train_file, indent=4)\n",
    "\n",
    "# Write the validation data to 'human_scanpath_valid_split.json'\n",
    "with open(valid_file_path, 'w') as valid_file:\n",
    "    json.dump(valid_data, valid_file, indent=4)\n",
    "\n",
    "print(\"Data has been filtered, split, and written to the respective files.\")\n",
    "print(f\"Total entries after filtering: {len(data)}\")\n",
    "print(f\"Training entries: {len(train_data)}\")\n",
    "print(f\"Validation entries: {len(valid_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved resized image: Slide1.png to files/Stroop_DataSet/Stroop 512x320/congruent\n",
      "Saved resized image: Slide33.png to files/Stroop_DataSet/Stroop 512x320/congruent\n",
      "Saved resized image: Slide5.png to files/Stroop_DataSet/Stroop 512x320/congruent\n",
      "Saved resized image: Slide25.png to files/Stroop_DataSet/Stroop 512x320/congruent\n",
      "Saved resized image: Slide7.png to files/Stroop_DataSet/Stroop 512x320/congruent\n",
      "Saved resized image: Slide29.png to files/Stroop_DataSet/Stroop 512x320/congruent\n",
      "Saved resized image: Slide21.png to files/Stroop_DataSet/Stroop 512x320/congruent\n",
      "Saved resized image: Slide39.png to files/Stroop_DataSet/Stroop 512x320/congruent\n",
      "Saved resized image: Slide11.png to files/Stroop_DataSet/Stroop 512x320/congruent\n",
      "Saved resized image: Slide17.png to files/Stroop_DataSet/Stroop 512x320/incongruent\n",
      "Saved resized image: Slide9.png to files/Stroop_DataSet/Stroop 512x320/incongruent\n",
      "Saved resized image: Slide35.png to files/Stroop_DataSet/Stroop 512x320/incongruent\n",
      "Saved resized image: Slide19.png to files/Stroop_DataSet/Stroop 512x320/incongruent\n",
      "Saved resized image: Slide27.png to files/Stroop_DataSet/Stroop 512x320/incongruent\n",
      "Saved resized image: Slide15.png to files/Stroop_DataSet/Stroop 512x320/incongruent\n",
      "Saved resized image: Slide3.png to files/Stroop_DataSet/Stroop 512x320/incongruent\n",
      "Saved resized image: Slide37.png to files/Stroop_DataSet/Stroop 512x320/incongruent\n",
      "Saved resized image: Slide31.png to files/Stroop_DataSet/Stroop 512x320/incongruent\n",
      "Saved resized image: Slide13.png to files/Stroop_DataSet/Stroop 512x320/incongruent\n",
      "Saved resized image: Slide23.png to files/Stroop_DataSet/Stroop 512x320/incongruent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def resize_images(source_dir, dest_dir, size=(512, 320)):\n",
    "    # Create destination directory if it doesn't exist\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate over all files in the source directory\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):  # Check for image files\n",
    "            file_path = os.path.join(source_dir, filename)\n",
    "            with Image.open(file_path) as img:\n",
    "                # Resize image\n",
    "                img = img.resize(size)\n",
    "                # Save resized image to destination directory\n",
    "                img.save(os.path.join(dest_dir, filename))\n",
    "                print(f\"Saved resized image: {filename} to {dest_dir}\")\n",
    "\n",
    "# Do the resizing for the Stroop dataset (Congruent and Incongruent)\n",
    "source_directory = 'files/Stroop_DataSet/Stroop/congruent'\n",
    "destination_directory = 'files/Stroop_DataSet/Stroop 512x320/congruent'\n",
    "resize_images(source_directory, destination_directory)\n",
    "source_directory = 'files/Stroop_DataSet/Stroop/incongruent'\n",
    "destination_directory = 'files/Stroop_DataSet/Stroop 512x320/incongruent'\n",
    "resize_images(source_directory, destination_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute DCBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/Repos/Scanpath_Prediction/.venv/lib/python3.12/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved features for Slide 11.png\n",
      "Processed and saved features for Slide1.png\n",
      "Processed and saved features for Slide 39.png\n",
      "Processed and saved features for Slide 21.png\n",
      "Processed and saved features for Slide 33.png\n",
      "Processed and saved features for Slide 5.png\n",
      "Processed and saved features for Slide33.png\n",
      "Processed and saved features for Slide5.png\n",
      "Processed and saved features for Slide 1.png\n",
      "Processed and saved features for Slide25.png\n",
      "Processed and saved features for Slide 7.png\n",
      "Processed and saved features for Slide7.png\n",
      "Processed and saved features for Slide 25.png\n",
      "Processed and saved features for Slide 29.png\n",
      "Processed and saved features for Slide29.png\n",
      "Processed and saved features for Slide21.png\n",
      "Processed and saved features for Slide39.png\n",
      "Processed and saved features for Slide11.png\n",
      "Processed and saved features for Slide17.png\n",
      "Processed and saved features for Slide 27.png\n",
      "Processed and saved features for Slide9.png\n",
      "Processed and saved features for Slide35.png\n",
      "Processed and saved features for Slide 13.png\n",
      "Processed and saved features for Slide 15.png\n",
      "Processed and saved features for Slide19.png\n",
      "Processed and saved features for Slide27.png\n",
      "Processed and saved features for Slide15.png\n",
      "Processed and saved features for Slide3.png\n",
      "Processed and saved features for Slide 31.png\n",
      "Processed and saved features for Slide 9.png\n",
      "Processed and saved features for Slide 23.png\n",
      "Processed and saved features for Slide 3.png\n",
      "Processed and saved features for Slide 17.png\n",
      "Processed and saved features for Slide37.png\n",
      "Processed and saved features for Slide 19.png\n",
      "Processed and saved features for Slide 37.png\n",
      "Processed and saved features for Slide 35.png\n",
      "Processed and saved features for Slide31.png\n",
      "Processed and saved features for Slide13.png\n",
      "Processed and saved features for Slide23.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.modeling import build_backbone\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "def pred2feat(seg, info):\n",
    "    seg = seg.cpu()\n",
    "    feat = torch.zeros([80 + 54, 320, 512])\n",
    "    for pred in info:\n",
    "        mask = (seg == pred['id']).float()\n",
    "        if pred['isthing']:\n",
    "            feat[pred['category_id'], :, :] = mask * pred['score']\n",
    "        else:\n",
    "            feat[pred['category_id'] + 80, :, :] = mask\n",
    "    return F.interpolate(feat.unsqueeze(0), size=[20, 32]).squeeze(0)\n",
    "\n",
    "\n",
    "def get_DCBs(img_path, predictor, radius=1):\n",
    "    high = Image.open(img_path).convert('RGB').resize((512, 320))\n",
    "    low = high.filter(ImageFilter.GaussianBlur(radius=radius))\n",
    "    high_panoptic_seg, high_segments_info = predictor(\n",
    "        np.array(high))[\"panoptic_seg\"]\n",
    "    low_panoptic_seg, low_segments_info = predictor(\n",
    "        np.array(low))[\"panoptic_seg\"]\n",
    "    high_feat = pred2feat(high_panoptic_seg, high_segments_info)\n",
    "    low_feat = pred2feat(low_panoptic_seg, low_segments_info)\n",
    "    return high_feat, low_feat\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load pretrained panoptic_fpn\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(\n",
    "        './detectron2/configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml'\n",
    "    )\n",
    "    cfg.MODEL.WEIGHTS = 'detectron2://COCO-PanopticSegmentation/panoptic_fpn_R_50_3x/139514569/model_final_c10459.pkl'\n",
    "    model = build_backbone(cfg).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    # Specify directories\n",
    "    img_dir = 'files/Stroop_DataSet/Stroop 512x320'\n",
    "    hr_dir = 'files/Stroop_DataSet/DCBs/HR'\n",
    "    lr_dir = 'files/Stroop_DataSet/DCBs/LR'\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(hr_dir, exist_ok=True)\n",
    "    os.makedirs(lr_dir, exist_ok=True)\n",
    "\n",
    "    # Process each image file in the directory recursively\n",
    "    for root, dirs, files in os.walk(img_dir):\n",
    "        for img_filename in files:\n",
    "            # Check if the file is an image\n",
    "            if img_filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(root, img_filename)\n",
    "\n",
    "                # Get high and low resolution features\n",
    "                high_feat, low_feat = get_DCBs(img_path, predictor)\n",
    "                \n",
    "                # Create relative path and ensure the output directories exist\n",
    "                relative_path = os.path.relpath(root, img_dir)\n",
    "                hr_output_dir = os.path.join(hr_dir, relative_path)\n",
    "                lr_output_dir = os.path.join(lr_dir, relative_path)\n",
    "                \n",
    "                os.makedirs(hr_output_dir, exist_ok=True)\n",
    "                os.makedirs(lr_output_dir, exist_ok=True)\n",
    "\n",
    "                # Save features to HR and LR directories\n",
    "                image_filename = f'{img_filename.replace(\".png\", \"\").replace(\" \", \"\")}.pth.tar'\n",
    "                torch.save(high_feat, os.path.join(hr_output_dir, image_filename))\n",
    "                torch.save(low_feat, os.path.join(lr_output_dir, image_filename))\n",
    "\n",
    "                print(f\"Processed and saved features for {img_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWAP  Xs and Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Load the data from the fixation.json file\n",
    "# with open('files/Stroop_DataSet/stroop_human_scanpath_train_split.json', 'r') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# # Swap X and Y values for all entries\n",
    "# for entry in data:\n",
    "#     entry['X'], entry['Y'] = entry['Y'], entry['X']\n",
    "\n",
    "# # Save the modified data back to a new file\n",
    "# with open('files/Stroop_DataSet/stroop_human_scanpath_train_split.json', 'w') as file:\n",
    "#     json.dump(data, file, indent=4)\n",
    "\n",
    "#     # Load the data from the fixation.json file\n",
    "# with open('files/Stroop_DataSet/stroop_human_scanpath_valid_split.json', 'r') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# # Swap X and Y values for all entries\n",
    "# for entry in data:\n",
    "#     entry['X'], entry['Y'] = entry['Y'], entry['X']\n",
    "\n",
    "# # Save the modified data back to a new file\n",
    "# with open('files/Stroop_DataSet/stroop_human_scanpath_valid_split.json', 'w') as file:\n",
    "#     json.dump(data, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
